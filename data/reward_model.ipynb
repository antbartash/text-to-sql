{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe20728-8bcc-47fc-8148-a2144c58e259",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49d56f23-d923-4899-85c1-b91adf512c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from trl import RewardTrainer, RewardConfig\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import _config\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "import GPUtil\n",
    "import gc\n",
    "\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = _config.WANDB_API_KEY\n",
    "os.environ[\"WANDB_PROJECT\"] = _config.WANDB_PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55c654-917a-406c-bc81-201d4397e62f",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525fe697-fbe6-4939-a379-b320f0bf0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CPU 0 load: 3.00\n",
      "CPU 1 load: 1.00\n",
      "CPU 2 load: 0.00\n",
      "CPU 3 load: 0.00\n",
      "RAM Total: 27.40 GB, Used: 1.94 GB\n",
      "GPU 0 (Tesla T4) load: 0.0%\n",
      "GPU 0 (Tesla T4) VRAM Total: 16384.0 MB, Used 3.0 MB\n",
      "Disk Total: 60.95 GB, Used: 37.89 GB\n"
     ]
    }
   ],
   "source": [
    "def get_vm_usage_metrics():\n",
    "    # CPU usage\n",
    "    cpu_load = psutil.cpu_percent(interval=1, percpu=True)\n",
    "    for id, load in enumerate(cpu_load):\n",
    "        print(f\"CPU {id} load: {load:.2f}\")\n",
    "    # RAM usage\n",
    "    ram = psutil.virtual_memory()\n",
    "    print(f\"RAM Total: {ram.total/(1024**3):.2f} GB, Used: {(ram.used)/(1024**3):.2f} GB\")\n",
    "    # GPU\n",
    "    if torch.cuda.is_available():\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        for gpu in gpus:\n",
    "            print(f\"GPU {gpu.id} ({gpu.name}) load: {gpu.load*100}%\")\n",
    "            print(f\"GPU {gpu.id} ({gpu.name}) VRAM Total: {gpu.memoryTotal} MB, Used {gpu.memoryUsed} MB\")\n",
    "    # Disk \n",
    "    disk = psutil.disk_usage('/')\n",
    "    print(f\"Disk Total: {disk.total/(1024**3):.2f} GB, Used: {(disk.used)/(1024**3):.2f} GB\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')\n",
    "get_vm_usage_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f2fc14-5482-4a8c-b9cb-41410dbc89ec",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c19a40-edd8-4972-9a7e-b3ee05c35df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6943, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sql_prompt</th>\n",
       "      <th>sql_context</th>\n",
       "      <th>sql</th>\n",
       "      <th>model_used</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the average moisture level for each cr...</td>\n",
       "      <td>CREATE TABLE crop_moisture (id INT, crop_id IN...</td>\n",
       "      <td>SELECT type, AVG(moisture) as avg_moisture FRO...</td>\n",
       "      <td>meta-llama/llama-4-maverick-17b-128e-instruct</td>\n",
       "      <td>SELECT type, moisture as avg_moisture FROM cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Add a new job title called 'Data Science Manag...</td>\n",
       "      <td>CREATE TABLE JobTitle (JobTitleID INT PRIMARY ...</td>\n",
       "      <td>INSERT INTO JobTitle (JobTitleID, JobTitleName...</td>\n",
       "      <td>meta-llama/llama-4-maverick-17b-128e-instruct</td>\n",
       "      <td>INSERT INTO JobTitel (JobTitleID, JobTitleName...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the total number of military equipment...</td>\n",
       "      <td>CREATE TABLE MaintenanceRequests (RequestID IN...</td>\n",
       "      <td>SELECT COUNT(*) FROM MaintenanceRequests WHERE...</td>\n",
       "      <td>meta-llama/llama-4-scout-17b-16e-instruct</td>\n",
       "      <td>SELECT COUNT(*) FROM MaintenanceRequests WHERE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Insert a new record into the 'community_educat...</td>\n",
       "      <td>CREATE TABLE community_education (id INT, prog...</td>\n",
       "      <td>INSERT INTO community_education (id, program, ...</td>\n",
       "      <td>moonshotai/kimi-k2-instruct</td>\n",
       "      <td>\"INSERT INTO community_education (id, program,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many users signed up daily in the 'games' ...</td>\n",
       "      <td>CREATE TABLE signups (user_id INT, category TE...</td>\n",
       "      <td>SELECT DATE(timestamp) as signup_date, COUNT(D...</td>\n",
       "      <td>moonshotai/kimi-k2-instruct</td>\n",
       "      <td>SELECT DATE(timestamp) as signup_date, COUNT(u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sql_prompt  \\\n",
       "0  What is the average moisture level for each cr...   \n",
       "1  Add a new job title called 'Data Science Manag...   \n",
       "2  What is the total number of military equipment...   \n",
       "3  Insert a new record into the 'community_educat...   \n",
       "4  How many users signed up daily in the 'games' ...   \n",
       "\n",
       "                                         sql_context  \\\n",
       "0  CREATE TABLE crop_moisture (id INT, crop_id IN...   \n",
       "1  CREATE TABLE JobTitle (JobTitleID INT PRIMARY ...   \n",
       "2  CREATE TABLE MaintenanceRequests (RequestID IN...   \n",
       "3  CREATE TABLE community_education (id INT, prog...   \n",
       "4  CREATE TABLE signups (user_id INT, category TE...   \n",
       "\n",
       "                                                 sql  \\\n",
       "0  SELECT type, AVG(moisture) as avg_moisture FRO...   \n",
       "1  INSERT INTO JobTitle (JobTitleID, JobTitleName...   \n",
       "2  SELECT COUNT(*) FROM MaintenanceRequests WHERE...   \n",
       "3  INSERT INTO community_education (id, program, ...   \n",
       "4  SELECT DATE(timestamp) as signup_date, COUNT(D...   \n",
       "\n",
       "                                      model_used  \\\n",
       "0  meta-llama/llama-4-maverick-17b-128e-instruct   \n",
       "1  meta-llama/llama-4-maverick-17b-128e-instruct   \n",
       "2      meta-llama/llama-4-scout-17b-16e-instruct   \n",
       "3                    moonshotai/kimi-k2-instruct   \n",
       "4                    moonshotai/kimi-k2-instruct   \n",
       "\n",
       "                                          completion  \n",
       "0  SELECT type, moisture as avg_moisture FROM cro...  \n",
       "1  INSERT INTO JobTitel (JobTitleID, JobTitleName...  \n",
       "2  SELECT COUNT(*) FROM MaintenanceRequests WHERE...  \n",
       "3  \"INSERT INTO community_education (id, program,...  \n",
       "4  SELECT DATE(timestamp) as signup_date, COUNT(u...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('rm_data.xlsx')\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a877439d-6d01-46d1-a423-a87a84b2a81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 6248\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for id in range(data.shape[0]):\n",
    "    dataset.append({\n",
    "        'prompt': data.loc[id, 'sql_prompt'],\n",
    "        'chosen': data.loc[id, 'sql'],\n",
    "        'rejected': data.loc[id, 'completion']\n",
    "    })\n",
    "    \n",
    "dataset = Dataset.from_list(dataset)\n",
    "\n",
    "split = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "ds_train = split['train']\n",
    "ds_valid = split['test']\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd8f046-2cc9-4c40-b9a5-2ee9d98e19c1",
   "metadata": {},
   "source": [
    "# RM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d81214b5-35fd-4109-b4b7-4a36c258b177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rm-lr1e5-epochs1-2026-01-11_17-24-06</strong> at: <a href='https://wandb.ai/olialeshka-none/text-to-sql/runs/85e6jzfs' target=\"_blank\">https://wandb.ai/olialeshka-none/text-to-sql/runs/85e6jzfs</a><br> View project at: <a href='https://wandb.ai/olialeshka-none/text-to-sql' target=\"_blank\">https://wandb.ai/olialeshka-none/text-to-sql</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260111_172408-85e6jzfs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/olialeshka_1/wandb/run-20260111_172613-xelfuj1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/olialeshka-none/text-to-sql/runs/xelfuj1s' target=\"_blank\">rm-lr1e5-epochs1-2026-01-11_17-26-13</a></strong> to <a href='https://wandb.ai/olialeshka-none/text-to-sql' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/olialeshka-none/text-to-sql' target=\"_blank\">https://wandb.ai/olialeshka-none/text-to-sql</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/olialeshka-none/text-to-sql/runs/xelfuj1s' target=\"_blank\">https://wandb.ai/olialeshka-none/text-to-sql/runs/xelfuj1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2cd0b03ea0419ebc066473bbf39d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/6248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbdd3faaf274771929fa123ad1e0b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/6248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f409e3fb55f4bbdbb545cc1442a8349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering train >1024 tokens:   0%|          | 0/6248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9d96aacf424cae8056b02f02bd3078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74971235c6344b8288efa6a9721bd026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc40df0d3b2b42ef9abf92ffacee2c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering eval >1024 tokens:   0%|          | 0/695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Setup Summary =====\n",
      "Num epochs:            1\n",
      "Effective batch size:  16\n",
      "Per-device batch size: 2\n",
      "Gradient accumulation: 8\n",
      "Dataset size:          6248\n",
      "Steps per epoch:       390\n",
      "Total training steps:  390\n",
      "Warmup steps:          39\n",
      "Logging steps:         40\n",
      "===================================\n",
      "Start time: 2026-01-11_17-26-21\n",
      "Starting fresh training run\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='381' max='381' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [381/381 48:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Min Reward</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Max Reward</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.661800</td>\n",
       "      <td>0.483437</td>\n",
       "      <td>72963.000000</td>\n",
       "      <td>-6.532180</td>\n",
       "      <td>3.340088</td>\n",
       "      <td>10.953869</td>\n",
       "      <td>0.795387</td>\n",
       "      <td>1.083188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.241077</td>\n",
       "      <td>144365.000000</td>\n",
       "      <td>-10.846726</td>\n",
       "      <td>-0.738020</td>\n",
       "      <td>11.013393</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>3.763621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.205987</td>\n",
       "      <td>215066.000000</td>\n",
       "      <td>-9.399182</td>\n",
       "      <td>3.838975</td>\n",
       "      <td>15.412946</td>\n",
       "      <td>0.915923</td>\n",
       "      <td>6.183353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.202793</td>\n",
       "      <td>287460.000000</td>\n",
       "      <td>-7.064407</td>\n",
       "      <td>7.215848</td>\n",
       "      <td>16.869048</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>5.630406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.179696</td>\n",
       "      <td>359427.000000</td>\n",
       "      <td>-10.120164</td>\n",
       "      <td>2.419957</td>\n",
       "      <td>14.953125</td>\n",
       "      <td>0.931548</td>\n",
       "      <td>6.654533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.166673</td>\n",
       "      <td>432846.000000</td>\n",
       "      <td>-9.952381</td>\n",
       "      <td>3.237289</td>\n",
       "      <td>15.802827</td>\n",
       "      <td>0.938988</td>\n",
       "      <td>7.164189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.167084</td>\n",
       "      <td>510075.000000</td>\n",
       "      <td>-10.170387</td>\n",
       "      <td>3.341889</td>\n",
       "      <td>16.078125</td>\n",
       "      <td>0.933780</td>\n",
       "      <td>7.472739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.158692</td>\n",
       "      <td>585930.000000</td>\n",
       "      <td>-10.321057</td>\n",
       "      <td>2.801315</td>\n",
       "      <td>15.734375</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>7.326050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.164289</td>\n",
       "      <td>658661.000000</td>\n",
       "      <td>-10.338914</td>\n",
       "      <td>2.778903</td>\n",
       "      <td>15.737351</td>\n",
       "      <td>0.933780</td>\n",
       "      <td>7.324001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time: 2026-01-11_18-15-03\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "RUN_NAME = f'rm-lr1e5-epochs1-{timestamp}'\n",
    "OUTPUT_DIR = './rm-output'\n",
    "RESUME_TRAINING = False\n",
    "\n",
    "PER_DEVICE_BATCH_SIZE = 2\n",
    "effective_batch_size = 16\n",
    "epochs = 1\n",
    "learning_rate = 1e-5\n",
    "warmup_ratio = 0.1\n",
    "\n",
    "gradient_accumulation_steps = int(effective_batch_size / PER_DEVICE_BATCH_SIZE)\n",
    "\n",
    "wandb.init(\n",
    "    project=os.environ[\"WANDB_PROJECT\"],\n",
    "    name=RUN_NAME,\n",
    "    # id=run_id ,         # resume previous run if available\n",
    "    # resume=\"allow\",    # allows resuming crashed run\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Qwen/Qwen3-0.6B\", \n",
    "    dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "training_args = RewardConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=PER_DEVICE_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_epochs=epochs,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=gradient_accumulation_steps*5,\n",
    "    save_total_limit=2,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=gradient_accumulation_steps*5,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=gradient_accumulation_steps*5,\n",
    "    report_to=['wandb'],\n",
    "    run_name=RUN_NAME,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    max_grad_norm=1,\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    ")\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=25)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Training setup summary\n",
    "dataset_size = len(ds_train)\n",
    "steps_per_epoch = dataset_size // (PER_DEVICE_BATCH_SIZE * gradient_accumulation_steps)\n",
    "total_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(total_steps * warmup_ratio)\n",
    "\n",
    "print(\"===== Training Setup Summary =====\")\n",
    "print(f\"Num epochs:            {epochs}\")\n",
    "print(f\"Effective batch size:  {effective_batch_size}\")\n",
    "print(f\"Per-device batch size: {PER_DEVICE_BATCH_SIZE}\")\n",
    "print(f\"Gradient accumulation: {gradient_accumulation_steps}\")\n",
    "print(f\"Dataset size:          {dataset_size}\")\n",
    "print(f\"Steps per epoch:       {steps_per_epoch}\")\n",
    "print(f\"Total training steps:  {total_steps}\")\n",
    "print(f\"Warmup steps:          {warmup_steps}\")\n",
    "print(f\"Logging steps:         {training_args.logging_steps}\")\n",
    "print(\"===================================\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n",
    "\n",
    "\n",
    "# Training\n",
    "last_checkpoint = None\n",
    "if RESUME_TRAINING and os.path.isdir(OUTPUT_DIR):\n",
    "    last_checkpoint = get_last_checkpoint(OUTPUT_DIR)\n",
    "\n",
    "if last_checkpoint is not None:\n",
    "    print(f\"Resuming training from checkpoint: {last_checkpoint}\")\n",
    "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "else:\n",
    "    print(\"Starting fresh training run\")\n",
    "    trainer.train()\n",
    "\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8978293a-2f92-4370-b6f1-e4bd7bb959dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"{OUTPUT_DIR}/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "240072f4-071f-48f0-a5a8-7b97df4bddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    f\"{OUTPUT_DIR}/best_model\",\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e8ca0-bfcf-4153-abdd-f333f8d85abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python t4",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
